{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alwOsIlVboj3"
   },
   "source": [
    "# Graded Exercise 2: Anomaly Detection on Acoustic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uvNdd91bvDF"
   },
   "source": [
    "- **Course**: [CIVIL-426 - Machine Learning for Predictive Maintenance](https://edu.epfl.ch/coursebook/en/machine-learning-for-predictive-maintenance-applications-CIVIL-426)\n",
    "- **Start Date**: 2024.10.03 at 10:15\n",
    "- **Due Date**: 2024.10.23 at 23:59\n",
    "- **Student 0**:\n",
    "    - Name: `Viktor Kjellsson`\n",
    "    - SCIPER: `396 802`\n",
    "- **Student 1**:\n",
    "    - Name: `Mathis Magnin`\n",
    "    - SCIPER: `327 838`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Anomalous sound detection (ASD) refers to the task of identifying whether the sounds emitted from a target machine are normal or anomalous.\n",
    "In real-world industrial environments, anomalies are infrequent and can exhibit significant variability, making it impractical to build an exhaustive set of anomalous sound patterns.\n",
    "As a result, our goal is to detect anomalous sounds using only normal sound clips for training.\n",
    "\n",
    "This challenge cannot be approached as a simple classification problem (anomaly vs healthy). Instead, it is formulated as a **one-class classification** problem, where the model is trained on normal sound data to detect deviations from the learned pattern.\n",
    "\n",
    "Anomalous sound detection can be achieved with following steps:\n",
    "   - Feature Extraction (I)\n",
    "   - One-class Classifier Training (II)\n",
    "   - Decisions based on a threshold from your trained classifier (III)\n",
    "   \n",
    "Through this assignment, you will primarily focus on tasks (I) and (II).\n",
    "The quality of your one-class classifier will be assessed using the **Area Under the Curve (AUC)** score on the test dataset.\n",
    "\n",
    "The model used here is a type of neural network called **AutoEncoder** (AE). AE is trained to reconstruct the input data while compressing the input data into a lower-dimensional latent space and minimizing information loss during this process.\n",
    "Thus, you will also modify the extracted features and Neural Network used in this notebook to improve the anomalous sound detection performance.\n",
    "\n",
    "The dataset is composed of two different machines, a Pump and a Valve. For each machine you have:\n",
    "- A **training dataset** composed of *only healthy* sound data\n",
    "- A **test dataset** composed of *both healthy and abnormal* sound data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "\n",
    "Your task is to improve the anomalous sound detection performance by modifying the feature extraction process and neural network architecture. You are expected to experiment with various feature representations and neural network configurations to optimize detection results.\n",
    "\n",
    "Specifically, the following questions must be addressed. Each question should be discussed separately for both the Pump and Valve datasets. The answers are to be provided in a PDF report, and the full Jupyter notebook must also be submitted.\n",
    "\n",
    "**Question 1:** Given the provided code, fill in the blank spaces to extract signal features, train a simple AutoEncoder that reconstructs the inputs MEL-Spectogram, and report the AUC score.\n",
    "\n",
    "**Question 2:** From the trained AutoEncoder, use the bottleneck features to train both (1) a One-Class SVM and (2) an Isolation Forest, and report the corresponding AUC scores.\n",
    "\n",
    "**Question 3:** Instead of using AutoEncoder features, apply PCA to project the MEL-spectrogram into a smaller dimensional space, then train (1) a One-Class SVM and (2) an Isolation Forest, and report the AUC scores.\n",
    "\n",
    "**Question 4:** Determine an appropriate threshold for distinguishing anomalies based on the given results, and compute the following metrics: Accuracy, True Positive Rate (TPR), False Positive Rate (FPR), and F1-score.\n",
    "\n",
    "**Question 5:** Visualize essential steps and provide a thorough discussion of the results obtained from all the methods.  \n",
    "\n",
    "**Bonus Question:** Modify the AutoEncoder architecture to a 2D AutoEncoder using convolutional layers instead of fully connected layers, and analyze its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AalklIEQg09y"
   },
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gdown --upgrade --quiet\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pump Dataset\n",
    "gdown.download(id='1ZAqnNW2gnHDyFHGHk3Aru7k-ng-BTpGn', output=\"./dev_data_pump_04.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valve Dataset\n",
    "gdown.download(id='1H_SS7qteLcd44e5CD9CFJjhJ573FAb6M', output=\"./dev_data_valve_00.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case that above links do not work, you can also manully download the dataset here:\n",
    "- **dev_data_pump_04.zip**: https://docs.google.com/uc?export=download&id=1ZAqnNW2gnHDyFHGHk3Aru7k-ng-BTpGn\n",
    "- **dev_data_valve_00,zip**: https://docs.google.com/uc?export=download&id=1H_SS7qteLcd44e5CD9CFJjhJ573FAb6M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MgKKujQsg3R6",
    "outputId": "20831466-937b-4715-b210-f298dbecf5b1"
   },
   "outputs": [],
   "source": [
    "\n",
    "!unzip -o dev_data_pump_04.zip\n",
    "!unzip -o dev_data_valve_00.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "vnb2HZBvg8FQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a subfolder in the current project directory\n",
    "output_dir = 'Figures_Valve'\n",
    "\n",
    "# Create the subfolder if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rj7toOo8g93H"
   },
   "source": [
    "## Audio Data Loading and MEL-Spectrogram Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uO8WNShag_tM"
   },
   "source": [
    "The code is adapted from https://github.com/MIMII-hitachi/mimii_baseline\n",
    "\n",
    "Copyright (C) 2019 Hitachi, Ltd. All right reserved.\n",
    "\n",
    "Harsh Purohit, Ryo Tanabe, Kenji Ichige, Takashi Endo, Yuki Nikaido, Kaori Suefusa, and Yohei Kawaguchi, \"MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection,\" arXiv preprint arXiv:1909.09347, 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# import additional python-library\n",
    "########################################################################\n",
    "import librosa.core\n",
    "import librosa.feature\n",
    "\n",
    "# WAV File Input\n",
    "def load_wav_files(wav_file_name, mono=True):\n",
    "    \"\"\"Load a .wav file.\"\"\"\n",
    "    try:\n",
    "        return librosa.load(wav_file_name, sr=None, mono=mono)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load file '{wav_file_name}'. Error: {e}\")\n",
    "        raise\n",
    "\n",
    "def demux_wav_files(wav_file_name, channel=0):\n",
    "    \"\"\"Demux a .wav file and return a specific channel.\"\"\"\n",
    "    try:\n",
    "        multi_channel_data, sr = load_wav_files(wav_file_name, mono=False)\n",
    "        if multi_channel_data.ndim == 1:\n",
    "            return sr, multi_channel_data\n",
    "        return sr, multi_channel_data[channel, :]\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in demuxing file '{wav_file_name}': {e}\")\n",
    "        raise\n",
    "\n",
    "# Feel free to modify and analysis the images in your report\n",
    "def plot_signals(tmin, tmax, sr, y, emphasized_y, log_mel_spectrogram):\n",
    "    # Raw Signal\n",
    "    plt.figure(1)\n",
    "    n = len(y)\n",
    "    t = np.linspace(tmin, tmax, n)\n",
    "    plt.plot(t, y)\n",
    "    plt.xlim(t[0],t[-1])\n",
    "    plt.xlabel('time/s',fontsize=20)\n",
    "    plt.ylabel('Amplitude',fontsize=20)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.grid()\n",
    "    # load the figure\n",
    "    file_path = os.path.join(output_dir, 'raw_pump.png')\n",
    "    plt.savefig(file_path, dpi=300)\n",
    "    \n",
    "    #FFT\n",
    "    plt.figure(2)\n",
    "    freq = sr/n*np.linspace(0,n/2,int(n/2)+1)\n",
    "    plt.plot(freq,np.absolute(np.fft.rfft(y[tmin*sr:tmax*sr],n)**2)/n)\n",
    "    plt.xlim(0,5000)\n",
    "    plt.xlabel('Frequency/Hz',fontsize=14)\n",
    "    # load the figure\n",
    "    file_path = os.path.join(output_dir, 'fft_pump.png')\n",
    "    plt.savefig(file_path, dpi=300)\n",
    "    \n",
    "    # FFT emphasized\n",
    "    plt.figure(3)\n",
    "    plt.plot(freq,np.absolute(np.fft.rfft(emphasized_y,n)**2)/n)\n",
    "    plt.xlim(0,5000)\n",
    "    plt.xlabel('Frequency/Hz',fontsize=14)\n",
    "    # load the figure\n",
    "    file_path = os.path.join(output_dir, 'fft_em_pump.png')\n",
    "    plt.savefig(file_path, dpi=300)\n",
    "    \n",
    "    # Spectogram\n",
    "    plt.figure(4)\n",
    "    librosa.display.specshow(log_mel_spectrogram)\n",
    "    plt.colorbar()\n",
    "    # load the figure\n",
    "    file_path = os.path.join(output_dir, 'spectro_pump.png')\n",
    "    plt.savefig(file_path, dpi=300)\n",
    "\n",
    "########################################################################\n",
    "# Feature Extractor\n",
    "########################################################################\n",
    "def file_to_features(file_name,\n",
    "                     n_mels=64,\n",
    "                     frames=5,\n",
    "                     n_fft=1024,\n",
    "                     hop_length=512,\n",
    "                     power=2.0,\n",
    "                     plot=True):\n",
    "    \"\"\"Convert a WAV file to a vector array.\"\"\"\n",
    "    # Step 01: Load the demuxed wav files\n",
    "    sr, y = demux_wav_files(file_name, channel=0)\n",
    "    \n",
    "    # Step 02: Signal Pre-emphasis\n",
    "    tmin = int(0)\n",
    "    tmax = int(len(y)/sr)\n",
    "    alpha = 0.95\n",
    "    emphasized_y = np.append(y[0],\n",
    "                             y[1:] - alpha*y[:-1])\n",
    "    \n",
    "    # Step 03: Generate MEL-Spectrogram\n",
    "    # ===================================\n",
    "    # IMPLEMENT YOUR CODE HERE\n",
    "    S = librosa.feature.melspectrogram(y=emphasized_y, sr=sr, n_fft=n_fft, hop_length=hop_length,power=power, n_mels=n_mels)\n",
    "    # ===================================\n",
    "\n",
    "    # Step 04: Convert MEL-Spectrogram to log scale\n",
    "    # ===================================\n",
    "    # IMPLEMENT YOUR CODE HERE\n",
    "    log_mel_spectrogram = librosa.power_to_db(S=S)\n",
    "    # ===================================\n",
    "    \n",
    "    \n",
    "    # Step 05: Define Feature Vector Array\n",
    "    dims = n_mels * frames\n",
    "    length = len(log_mel_spectrogram[0,:]) - frames + 1\n",
    "    features = np.zeros((length, dims), float)\n",
    "    \n",
    "    # Pad short clips instead of skipping\n",
    "    if length < 1:\n",
    "        print(f\"Audio file '{file_name}' is too short. Padding applied.\")\n",
    "        log_mel_spectrogram = np.pad(log_mel_spectrogram, ((0, 0), (0, frames - 1)), mode='constant')\n",
    "        length = 1\n",
    "    \n",
    "    for t in range(frames):\n",
    "        features[:, n_mels * t: n_mels * (t + 1)] = log_mel_spectrogram[:, t: t + length].T\n",
    "    \n",
    "    if plot:\n",
    "        plot_signals(tmin, tmax, sr, y, emphasized_y, log_mel_spectrogram)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_test_file = 'dev_data_valve_00/valve/train/normal_id_00_00000000.wav'\n",
    "# wav_test_file = 'dev_data_valve_00/valve/test/anomaly_id_00_00000000.wav'\n",
    "\n",
    "# Visualize your results for potential analysis in your report\n",
    "features = file_to_features(wav_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRqlvEaHhCdu"
   },
   "source": [
    "## PyTorch Dataset Splitting\n",
    "\n",
    "To define and optimize a neural network, we will use the library [PyTorch](http://pytorch.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "wxyR8O5XhBEC"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \".\"\n",
    "MACHINE = \"valve_00\" # Choice between  \"valve_00\" or \"pump_04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "mwG3y3NnhNB7"
   },
   "outputs": [],
   "source": [
    "class MIMII(Dataset):\n",
    "    def __init__(self, root, machine, train=True, transform=None, target_transform=None):\n",
    "        if train:\n",
    "            self.audio_path = os.path.join(root, f\"dev_data_{machine}\", machine.split(\"_\")[0], \"train\")\n",
    "            self.audio_files = os.listdir(self.audio_path)\n",
    "            self.labels = [int(f.split(\"_\")[0] == \"anomaly\") for f in self.audio_files]\n",
    "        else:\n",
    "            self.audio_path = os.path.join(root, f\"dev_data_{machine}\", machine.split(\"_\")[0], \"test\")\n",
    "            self.audio_files = os.listdir(self.audio_path)\n",
    "            self.labels = [int(f.split(\"_\")[0] == \"anomaly\") for f in self.audio_files]\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.audio_path, self.audio_files[idx])\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            f = self.transform(file_path)\n",
    "        else:\n",
    "            # default feature representation\n",
    "            f = file_to_features(file_path).astype(np.float32)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return f, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "oZTnxItehN89"
   },
   "outputs": [],
   "source": [
    "# Parameters of the feature extraction\n",
    "melsp_params = dict(n_mels=64,\n",
    "                    frames=1,\n",
    "                    n_fft=1024,\n",
    "                    hop_length=512,\n",
    "                    power=2.0,\n",
    "                    plot=False)\n",
    "\n",
    "\n",
    "feature_extraction_pipeline = T.Compose([\n",
    "    T.Lambda(lambda file: file_to_features(file, **melsp_params).astype(np.float32)),\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9MJSPhoPhO89",
    "outputId": "da5765b4-92e2-476f-9704-4ba4649d6647"
   },
   "outputs": [],
   "source": [
    "# Pytorch train/test datasets\n",
    "data_train = MIMII(\n",
    "    root=DATA_PATH,\n",
    "    machine=MACHINE,\n",
    "    train=True,\n",
    "    transform=feature_extraction_pipeline\n",
    ")\n",
    "\n",
    "data_test = MIMII(\n",
    "    root=DATA_PATH,\n",
    "    machine=MACHINE,\n",
    "    train=False,\n",
    "    transform=feature_extraction_pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0C0UJWihYFB"
   },
   "source": [
    "## AutoEncoder Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "E8jSz2BphWSl"
   },
   "outputs": [],
   "source": [
    "class DenseAutoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super(DenseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            )\n",
    "        \n",
    "        # TODO : write a symetrical neural network to the encoder to reconstuct the input\n",
    "        # ===================================\n",
    "        # IMPLEMENT YOUR CODE HERE\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim,),\n",
    "        )\n",
    "        # ===================================\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature = self.encoder(x)\n",
    "        reconstruction = self.decoder(feature)\n",
    "        return reconstruction,feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvFfKbfzhkIA",
    "outputId": "9c63a462-ac42-4782-a909-178bd268d426"
   },
   "outputs": [],
   "source": [
    "duration = 10  # s\n",
    "sr = 16000  # Hz\n",
    "input_dim = int(duration * sr / melsp_params[\"hop_length\"] + 1) * melsp_params[\"n_mels\"] * melsp_params[\"frames\"]\n",
    "model = DenseAutoencoder(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlKwicqPh4WN"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "b8TUxt5Lhkoh"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "J5r_42qUh6F7"
   },
   "outputs": [],
   "source": [
    "# PyTorch data loaders allow to iterate batch-wise over a dataset\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "2PLm0cEGh6yG"
   },
   "outputs": [],
   "source": [
    "# Stochastic gradient descent optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Mean Squared Error (MSE) loss function to be minimized\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "vCWTbrx0h829"
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, print_every=10):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    loss_running = 0\n",
    "    for batch, (x, y) in enumerate(tqdm(dataloader)):\n",
    "        # Compute prediction and loss\n",
    "        x = x.flatten(start_dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        x_pred, features = model(x)\n",
    "        \n",
    "        # TODO : write the loss function, compute the gradient, and update the model parameters\n",
    "        # ===================================\n",
    "        # IMPLEMENT YOUR CODE HERE\n",
    "        loss = loss_fn(x, x_pred) # from the previous cell\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        # ===================================\n",
    "        \n",
    "        # Back Propagation\n",
    "        loss_running += loss.item()\n",
    "    print(f\"loss: {loss_running/len(dataloader):>7f}\")\n",
    "\n",
    "\n",
    "def test_loop(dataset, model, loss_fn):\n",
    "    size = len(dataset)\n",
    "    test_losses = np.zeros(size)\n",
    "    store_feature = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, _) in enumerate(dataset):\n",
    "            x = x.flatten()\n",
    "            x_pred,features = model(x)\n",
    "            store_feature.append(features.detach().cpu().numpy())\n",
    "            test_losses[idx] = loss_fn(x_pred, x).item()\n",
    "\n",
    "    return test_losses, np.array(store_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izqhJT_siUAF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer, print_every=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOq7aGUribck"
   },
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uS8VF6qOicRh"
   },
   "outputs": [],
   "source": [
    "y_true = data_test.labels\n",
    "test_losses, extracted_features_test = test_loop(data_test, model, loss_fn)\n",
    "y_scores = test_losses\n",
    "\n",
    "metrics.roc_auc_score(y_true, y_scores)\n",
    "\n",
    "# TODO : Define a threshold based on test loss for classification\n",
    "# TODO : Report accuracy, TPR, FPR, F1-Score\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "\n",
    "# Generate thresholds from 0 to the maximum score\n",
    "thresholds = np.linspace(min(y_scores), max(y_scores), 100)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Calculate precision, recall, and F1 score for each threshold\n",
    "for threshold in thresholds:\n",
    "    # Convert scores to binary predictions\n",
    "    y_pred = [1 if score > threshold else 0 for score in y_scores]\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    precision = metrics.precision_score(y_true, y_pred)\n",
    "    recall = metrics.recall_score(y_true, y_pred)\n",
    "    f1 = metrics.f1_score(y_true, y_pred)\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "# Find the best threshold\n",
    "best_accuracy_threshold = thresholds[np.argmax(accuracy_list)]\n",
    "best_precision_threshold = thresholds[np.argmax(precision_list)]\n",
    "best_recall_threshold = thresholds[np.argmax(recall_list)]\n",
    "best_f1_threshold = thresholds[np.argmax(f1_list)]\n",
    "\n",
    "print(\"Loss values:\")\n",
    "print(f\"Best Accuracy Threshold: {best_accuracy_threshold:.2f}\")\n",
    "print(f\"Best Precision Threshold: {best_precision_threshold:.2f}\")\n",
    "print(f\"Best Recall Threshold: {best_recall_threshold:.2f}\")\n",
    "print(f\"Best F1 Threshold: {best_f1_threshold:.2f}\")\n",
    "'''\n",
    "##########################\n",
    "###### Accuracy based results ###########\n",
    "print(\"\\nAccuracy based\")\n",
    "y_pred = [1 if score > best_accuracy_threshold else 0 for score in y_scores]\n",
    "\n",
    "# metrics\n",
    "accuracy_autoencoder = metrics.accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "precision_autoencoder = metrics.precision_score(y_true=y_true, y_pred=y_pred)\n",
    "recall_autoencoder = metrics.recall_score(y_true=y_true, y_pred=y_pred)\n",
    "f1_autoencoder = metrics.f1_score(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_autoencoder:.2f}\")\n",
    "print(f\"Precision: {precision_autoencoder:.2f}\")\n",
    "print(f\"Recall: {recall_autoencoder:.2f}\")\n",
    "print(f\"F1: {f1_autoencoder:.2f}\")\n",
    "\n",
    "########Precision based results ##########\n",
    "print(\"\\nPrecision based\")\n",
    "y_pred = [1 if score > best_precision_threshold else 0 for score in y_scores]\n",
    "\n",
    "# metrics\n",
    "accuracy_autoencoder = metrics.accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "precision_autoencoder = metrics.precision_score(y_true=y_true, y_pred=y_pred)\n",
    "recall_autoencoder = metrics.recall_score(y_true=y_true, y_pred=y_pred)\n",
    "f1_autoencoder = metrics.f1_score(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_autoencoder:.2f}\")\n",
    "print(f\"Precision: {precision_autoencoder:.2f}\")\n",
    "print(f\"Recall: {recall_autoencoder:.2f}\")\n",
    "print(f\"F1: {f1_autoencoder:.2f}\")\n",
    "\n",
    "##########################\n",
    "###### Recall based results ###########\n",
    "print(\"\\nRecall based\")\n",
    "y_pred = [1 if score > best_recall_threshold else 0 for score in y_scores]\n",
    "\n",
    "# metrics\n",
    "accuracy_autoencoder = metrics.accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "precision_autoencoder = metrics.precision_score(y_true=y_true, y_pred=y_pred)\n",
    "recall_autoencoder = metrics.recall_score(y_true=y_true, y_pred=y_pred)\n",
    "f1_autoencoder = metrics.f1_score(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_autoencoder:.2f}\")\n",
    "print(f\"Precision: {precision_autoencoder:.2f}\")\n",
    "print(f\"Recall: {recall_autoencoder:.2f}\")\n",
    "print(f\"F1: {f1_autoencoder:.2f}\")\n",
    "'''\n",
    "##########################\n",
    "###### F1 based results ###########\n",
    "print(\"\\nF1 based\")\n",
    "y_pred = [1 if score > best_f1_threshold else 0 for score in y_scores]\n",
    "\n",
    "# metrics\n",
    "accuracy_autoencoder = metrics.accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "precision_autoencoder = metrics.precision_score(y_true=y_true, y_pred=y_pred)\n",
    "recall_autoencoder = metrics.recall_score(y_true=y_true, y_pred=y_pred)\n",
    "f1_autoencoder = metrics.f1_score(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_autoencoder:.2f}\")\n",
    "print(f\"Precision: {precision_autoencoder:.2f}\")\n",
    "print(f\"Recall: {recall_autoencoder:.2f}\")\n",
    "print(f\"F1: {f1_autoencoder:.2f}\")\n",
    "\n",
    "###########################\n",
    "print(f\"Final threshold choice : {best_f1_threshold:.2f}\")\n",
    "\n",
    "########################### (Fancy part)\n",
    "#CROSS-VALIDATION F1 based :\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Lists to store F1 scores and best thresholds from each fold\n",
    "f1_scores_cv = []\n",
    "thresholds_cv = []\n",
    "\n",
    "for train_index, test_index in kf.split(y_scores):\n",
    "    # Split the data into training and testing sets for each fold\n",
    "    y_scores_train, y_scores_test = np.array(y_scores)[train_index], np.array(y_scores)[test_index]\n",
    "    y_true_train, y_true_test = np.array(y_true)[train_index], np.array(y_true)[test_index]\n",
    "    \n",
    "    # Recalculate the best F1 threshold for this fold\n",
    "    thresholds_fold = np.linspace(min(y_scores_train), max(y_scores_train), 100)\n",
    "    f1_list_fold = []\n",
    "    \n",
    "    for threshold in thresholds_fold:\n",
    "        y_pred_train = [1 if score > threshold else 0 for score in y_scores_train]\n",
    "        f1_fold = metrics.f1_score(y_true_train, y_pred_train)\n",
    "        f1_list_fold.append(f1_fold)\n",
    "    \n",
    "    # Best threshold for this fold\n",
    "    best_f1_threshold_fold = thresholds_fold[np.argmax(f1_list_fold)]\n",
    "    thresholds_cv.append(best_f1_threshold_fold)\n",
    "    \n",
    "    # Apply the best F1 threshold from this fold on the test set\n",
    "    y_pred_cv = [1 if score > best_f1_threshold_fold else 0 for score in y_scores_test]\n",
    "    f1_cv = metrics.f1_score(y_true_test, y_pred_cv)\n",
    "    f1_scores_cv.append(f1_cv)\n",
    "\n",
    "# Calculate mean and standard deviation of F1 scores across folds\n",
    "mean_f1_cv = np.mean(f1_scores_cv)\n",
    "std_f1_cv = np.std(f1_scores_cv)\n",
    "\n",
    "# Calculate mean and standard deviation of thresholds across folds\n",
    "mean_threshold_cv = np.mean(thresholds_cv)\n",
    "std_threshold_cv = np.std(thresholds_cv)\n",
    "\n",
    "###########################\n",
    "# Reporting results\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"Mean F1 Score: {mean_f1_cv:.2f}\")\n",
    "print(f\"F1 Score Standard Deviation: {std_f1_cv:.2f}\")\n",
    "print(f\"Mean Best Threshold: {mean_threshold_cv:.10f}\")\n",
    "print(f\"Threshold Standard Deviation: {std_threshold_cv:.10f}\")\n",
    "\n",
    "###########################\n",
    "# Confidence in the threshold\n",
    "confidence_interval = 1.96 * (std_threshold_cv / np.sqrt(len(thresholds_cv)))  # 95% confidence interval\n",
    "\n",
    "print(f\"\\nConfidence in the best F1 threshold:\")\n",
    "print(f\"Threshold Confidence Interval: {mean_threshold_cv:.10f} ± {confidence_interval:.10f}\")\n",
    "\n",
    "\n",
    "\n",
    "# ==================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GlPy8HiSigc2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "RocCurveDisplay.from_predictions(y_true, -y_scores, name=\"Autoencoder\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.title(f\"Receiver operating characteristic (ROC) curve for {MACHINE}\");\n",
    "# load the figure\n",
    "file_path = os.path.join(output_dir, 'ROC_autoencoder.png')\n",
    "plt.savefig(file_path, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFWXKbjFiiO4"
   },
   "source": [
    "## One-Class SVM and Isolation Forest\n",
    "\n",
    "From the trained AutoEncoder, use the bottleneck features to train a (1) One-Class SVM and (2) Isolation Forest, and report the accuracy, F1-score and auc score of each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "yutJPQg5ioih"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "cpnrmvn7i8hn"
   },
   "outputs": [],
   "source": [
    "# Get normal training features\n",
    "y_pred_train, extracted_features_train = test_loop(data_train, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX-BDH08i8_H"
   },
   "source": [
    "### One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zzmxgn7iik37"
   },
   "outputs": [],
   "source": [
    "# TODO : Define the OneClassSVM here\n",
    "# TODO : Fit OneClassSVM here using training data\n",
    "# TODO : Report essential evaluation metrics\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "\n",
    "# OneClassSVM\n",
    "clf = OneClassSVM(gamma='scale').fit(extracted_features_train) # 'scale' : automatically adjusts based on the data distribution\n",
    "y_pred_clf = clf.predict(extracted_features_test)\n",
    "predicted_score = np.array([x if x == -1 else 0 for x in y_pred_clf]) # change +1 and -1 to fit the y_true standard\n",
    "\n",
    "# metrics\n",
    "accuracy_OneClassSVM = metrics.accuracy_score(y_true=y_true, y_pred=-predicted_score)\n",
    "precision_OneClassSVM = metrics.precision_score(y_true=y_true, y_pred=-predicted_score)\n",
    "recall_OneClassSVM = metrics.recall_score(y_true=y_true, y_pred=-predicted_score)\n",
    "f1_OneClassSVM = metrics.f1_score(y_true=y_true, y_pred=-predicted_score)\n",
    "\n",
    "# prints\n",
    "print(f\"Accuracy: {accuracy_OneClassSVM:.2f}\")\n",
    "print(f\"Precision: {precision_OneClassSVM:.2f}\")\n",
    "print(f\"Recall: {recall_OneClassSVM:.2f}\")\n",
    "print(f\"F1: {f1_OneClassSVM:.2f}\")\n",
    "\n",
    "# plot\n",
    "y_scores = clf.score_samples(extracted_features_test)\n",
    "RocCurveDisplay.from_predictions(y_true, y_scores, name=\"Autoencoder\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.title(f\"Receiver operating characteristic (ROC) curve for {MACHINE}\");\n",
    "# load the figure\n",
    "file_path = os.path.join(output_dir, 'ROC_SVM_autoencoder_feature.png')\n",
    "plt.savefig(file_path, dpi=300)\n",
    "# ===================================\n",
    "metrics.roc_auc_score(y_true, -predicted_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ivg1xIdyjABG"
   },
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsO8gdmAi5Kg"
   },
   "outputs": [],
   "source": [
    "# TODO : Define IsolationForest here\n",
    "# TODO : Fit IsolationForest here using training data\n",
    "# TODO : Report essential evaluation metrics\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "\n",
    "# IsolationForest\n",
    "clf = IsolationForest(contamination=0.5).fit(extracted_features_train) # the contamination is estimated based on the test dataset\n",
    "y_pred_clf = clf.predict(extracted_features_test)\n",
    "predicted_score = np.array([x if x == -1 else 0 for x in y_pred_clf]) # change +1 and -1 to fit the y_true standard\n",
    "\n",
    "# metrics\n",
    "accuracy_IsolationForest = metrics.accuracy_score(y_true=y_true, y_pred=-predicted_score)\n",
    "precision_IsolationForest = metrics.precision_score(y_true=y_true, y_pred=-predicted_score)\n",
    "recall_IsolationForest = metrics.recall_score(y_true=y_true, y_pred=-predicted_score)\n",
    "f1_IsolationForest = metrics.f1_score(y_true=y_true, y_pred=-predicted_score)\n",
    "\n",
    "# prints\n",
    "print(f\"Accuracy: {accuracy_IsolationForest:.2f}\")\n",
    "print(f\"Precision: {precision_IsolationForest:.2f}\")\n",
    "print(f\"Recall: {recall_IsolationForest:.2f}\")\n",
    "print(f\"F1: {f1_IsolationForest:.2f}\")\n",
    "\n",
    "# plot\n",
    "y_scores = clf.score_samples(extracted_features_test)\n",
    "RocCurveDisplay.from_predictions(y_true, y_scores, name=\"Autoencoder\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.title(f\"Receiver operating characteristic (ROC) curve for {MACHINE}\");\n",
    "# load the figure\n",
    "file_path = os.path.join(output_dir, 'ROC_Forest_autoencoder_feature.png')\n",
    "plt.savefig(file_path, dpi=300)\n",
    "\n",
    "# ===================================\n",
    "metrics.roc_auc_score(y_true, -predicted_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_5bTEeMjMoR"
   },
   "source": [
    "PCA of the spectrograms to reduce the input dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "a0UHfthQjQ_h"
   },
   "outputs": [],
   "source": [
    "# Extract spectrograms of training and testing\n",
    "flatten_spectogram_train = []\n",
    "for idx, (x, _) in enumerate(data_train):\n",
    "    x = x.flatten()\n",
    "    flatten_spectogram_train.append(x.numpy())\n",
    "train_spec = np.array(flatten_spectogram_train)\n",
    "\n",
    "flatten_spectogram_test = []\n",
    "for idx, (x, _) in enumerate(data_test):\n",
    "    x = x.flatten()\n",
    "    flatten_spectogram_test.append(x.numpy())\n",
    "test_spec = np.array(flatten_spectogram_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYVoyGx8jWKA"
   },
   "source": [
    "Apply PCA to fit and transform the training data and transform also the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4U1oqcStjep0"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=64)\n",
    "\n",
    "# TODO : Fit and transform the training data (train_spec)\n",
    "# TODO : Transform the testing data (test_spec)\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "\n",
    "print(train_spec.shape)\n",
    "print(test_spec.shape)\n",
    "\n",
    "x_train = pca.fit_transform(train_spec)\n",
    "x_test = pca.transform(test_spec)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# ==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcEezkFDjrL6"
   },
   "source": [
    "Apply OneClassSVM and IsolationForest on the new PCA features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Define the OneClassSVM here\n",
    "# TODO : Fit OneClassSVM here using PCA features\n",
    "# TODO : Report essential evaluation metrics\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "\n",
    "# OneClassSVM\n",
    "clf = OneClassSVM(gamma='scale').fit(x_train) # train dataset\n",
    "y_pred_clf = clf.predict(x_test)\n",
    "predicted_score = np.array([x if x == -1 else 0 for x in y_pred_clf]) # change +1 and -1 to fit the y_true standard\n",
    "\n",
    "# metrics\n",
    "accuracy_OneClassSVM = metrics.accuracy_score(y_true=y_true, y_pred=-predicted_score)\n",
    "precision_OneClassSVM = metrics.precision_score(y_true=y_true, y_pred=-predicted_score)\n",
    "recall_OneClassSVM = metrics.recall_score(y_true=y_true, y_pred=-predicted_score)\n",
    "f1_OneClassSVM = metrics.f1_score(y_true=y_true, y_pred=-predicted_score)\n",
    "\n",
    "# prints\n",
    "print(f\"Accuracy: {accuracy_OneClassSVM:.2f}\")\n",
    "print(f\"Precision: {precision_OneClassSVM:.2f}\")\n",
    "print(f\"Recall: {recall_OneClassSVM:.2f}\")\n",
    "print(f\"F1: {f1_OneClassSVM:.2f}\")\n",
    "\n",
    "# plot\n",
    "y_scores = clf.score_samples(x_test)\n",
    "RocCurveDisplay.from_predictions(y_true, y_scores, name=\"Autoencoder\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.title(f\"Receiver operating characteristic (ROC) curve for {MACHINE}\");\n",
    "# load the figure\n",
    "file_path = os.path.join(output_dir, 'ROC_SVM_PCA_feature.png')\n",
    "plt.savefig(file_path, dpi=300)\n",
    "\n",
    "# ===================================\n",
    "\n",
    "metrics.roc_auc_score(y_true, -predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Define IsolationForest here\n",
    "# TODO : Fit IsolationForest here using PCA features\n",
    "# TODO : Report essential evaluation metrics\n",
    "# ===================================\n",
    "# IMPLEMENT YOUR CODE HERE\n",
    "\n",
    "# IsolationForest\n",
    "clf = IsolationForest(contamination=0.5).fit(x_train) # train dataset\n",
    "y_pred_clf = clf.predict(x_test)\n",
    "predicted_score = np.array([x if x == -1 else 0 for x in y_pred_clf]) # change +1 and -1 to fit the y_true standard\n",
    "\n",
    "# metrics\n",
    "accuracy_IsolationForest = metrics.accuracy_score(y_true=y_true, y_pred=-predicted_score)\n",
    "precision_IsolationForest = metrics.precision_score(y_true=y_true, y_pred=-predicted_score)\n",
    "recall_IsolationForest = metrics.recall_score(y_true=y_true, y_pred=-predicted_score)\n",
    "f1_IsolationForest = metrics.f1_score(y_true=y_true, y_pred=-predicted_score)\n",
    "\n",
    "# prints\n",
    "print(f\"Accuracy: {accuracy_IsolationForest:.2f}\")\n",
    "print(f\"Precision: {precision_IsolationForest:.2f}\")\n",
    "print(f\"Recall: {recall_IsolationForest:.2f}\")\n",
    "print(f\"F1: {f1_IsolationForest:.2f}\")\n",
    "\n",
    "# plot\n",
    "y_scores = clf.score_samples(x_test)\n",
    "RocCurveDisplay.from_predictions(y_true, y_scores, name=\"Autoencoder\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.title(f\"Receiver operating characteristic (ROC) curve for {MACHINE}\");\n",
    "# load the figure\n",
    "file_path = os.path.join(output_dir, 'ROC_Forest_PCA_feature.png')\n",
    "plt.savefig(file_path, dpi=300)\n",
    "\n",
    "# ===================================\n",
    "\n",
    "metrics.roc_auc_score(y_true, -predicted_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "24ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
